{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d21c14e6-0804-4eb8-87fc-38f29ff47603",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastbook\n",
    "from fastbook import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35efc23b-cdc8-4621-a8d0-d35500fe13f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMixUp(Callback):\n",
    "    \"A handler class for implementing `MixUp` style scheduling\"\n",
    "    run_valid = False\n",
    "    def __init__(self, alpha=0.5):\n",
    "        self.distrib = Beta(tensor(alpha), tensor(alpha))\n",
    "\n",
    "    def before_train(self):\n",
    "        self.stack_y = getattr(self.learn.loss_func, 'y_int', False)\n",
    "        if self.stack_y: self.old_lf,self.learn.loss_func = self.learn.loss_func,self.lf\n",
    "\n",
    "    def after_train(self):\n",
    "        if self.stack_y: self.learn.loss_func = self.old_lf\n",
    "\n",
    "    def after_cancel_train(self):\n",
    "        self.after_train()\n",
    "\n",
    "    def before_batch(self):\n",
    "        lam = self.distrib.sample((self.y.size(0),)).squeeze().to(self.x.device)\n",
    "        lam = torch.stack([lam, 1-lam], 1)\n",
    "        self.lam = lam.max(1)[0]\n",
    "        shuffle = torch.randperm(self.y.size(0)).to(self.x.device)\n",
    "        xb1,self.yb1 = tuple(L(self.xb).itemgot(shuffle)),tuple(L(self.yb).itemgot(shuffle))\n",
    "        nx_dims = len(self.x.size())\n",
    "        self.learn.xb = tuple(L(xb1,self.xb).map_zip(torch.lerp,weight=unsqueeze(self.lam, n=nx_dims-1)))\n",
    "\n",
    "        if not self.stack_y:\n",
    "            ny_dims = len(self.y.size())\n",
    "            self.learn.yb = tuple(L(self.yb1,self.yb).map_zip(torch.lerp,weight=unsqueeze(self.lam, n=ny_dims-1)))\n",
    "            \n",
    "    def lf(self, pred, *yb):\n",
    "        if not self.training: return self.old_lf(pred, *yb)\n",
    "        with NoneReduce(self.old_lf) as lf:\n",
    "            loss = torch.lerp(lf(pred,*self.yb1), lf(pred,*yb), self.lam)\n",
    "        return reduce_loss(loss, getattr(self.old_lf, 'reduction', 'mean'))\n",
    "\n",
    "# Cell\n",
    "    \"Implementation of https://arxiv.org/abs/1710.09412\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21d116c-bf36-4c39-9711-8d575c93a673",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "path = untar_data(URLs.PETS)/'images'\n",
    "\n",
    "def is_cat(x): return x[0].isupper()\n",
    "dls = ImageDataLoaders.from_name_func(\n",
    "    path, get_image_files(path), valid_pct=0.2, seed=42,\n",
    "    label_func=is_cat, item_tfms=Resize(224))\n",
    "\n",
    "learn = cnn_learner(dls, resnet34, metrics=error_rate)\n",
    "learn.fine_tune(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
